{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c75bfdd",
   "metadata": {},
   "source": [
    "## Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14519f9",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f1ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e13e4481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0        1      2     3     4      5     6     7     8    9   10\n",
      "0      1  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0   1\n",
      "1      2  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0   1\n",
      "2      3  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0   1\n",
      "3      4  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0   1\n",
      "4      5  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0   1\n",
      "..   ...      ...    ...   ...   ...    ...   ...   ...   ...  ...  ..\n",
      "209  210  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0   7\n",
      "210  211  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0   7\n",
      "211  212  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0   7\n",
      "212  213  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0   7\n",
      "213  214  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0   7\n",
      "\n",
      "[214 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data\"\n",
    "data = pd.read_csv(url, header=None)\n",
    "print(data)\n",
    "\n",
    "# Split the data\n",
    "X = data.iloc[:, 1:-1]  # Features\n",
    "y = data.iloc[:, -1]   # Target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e833cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Cross-Validation Scores: [0.68571429 0.67647059 0.82352941 0.82352941 0.70588235]\n",
      "Random Forest - Mean Accuracy: 0.7430252100840337\n",
      "SVM - Cross-Validation Scores: [0.65714286 0.64705882 0.61764706 0.73529412 0.67647059]\n",
      "SVM - Mean Accuracy: 0.6667226890756304\n"
     ]
    }
   ],
   "source": [
    "# Model Exploration and Hyperparameter Tuning and perform hyperparameter tuning using Cross-Validation.\n",
    "# Model 1: Random Forest\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Model 2: Support Vector Machine (SVM)\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', SVC())\n",
    "])\n",
    "\n",
    "#Evaluate Models with Cross-Validation\n",
    "models = [\n",
    "    (\"Random Forest\", rf_pipeline),\n",
    "    (\"SVM\", svm_pipeline)\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"{name} - Cross-Validation Scores: {cv_scores}\")\n",
    "    print(f\"{name} - Mean Accuracy: {cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf4cf27",
   "metadata": {},
   "source": [
    "### Comments and Comparison the results:\n",
    "Random Forest:\n",
    "The Random Forest model shows relatively consistent performance across folds, with accuracy ranging from approximately 62.86% to 82.35%.\n",
    "The mean accuracy of around 73.16% indicates overall decent performance.\n",
    "\n",
    "SVM:\n",
    "The SVM model has varying performance across folds, with accuracy ranging from approximately 61.76% to 73.53%.\n",
    "The mean accuracy of around 66.67% suggests moderate performance.\n",
    "\n",
    "The Random Forest model generally outperforms the SVM model in terms of both mean accuracy and consistency across folds.\n",
    "Random Forest has a higher mean accuracy of 73.16% compared to SVM's 66.67%.While Random Forest appears to be the better-performing model in this evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c323a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - KFold CV Scores: [0.85714286 0.76470588 0.76470588 0.61764706 0.76470588]\n",
      "Random Forest - KFold Mean Accuracy: 0.753781512605042\n",
      "Random Forest - StratifiedKFold CV Scores: [0.65714286 0.70588235 0.73529412 0.73529412 0.76470588]\n",
      "Random Forest - StratifiedKFold Mean Accuracy: 0.7196638655462185\n",
      "Random Forest - LeaveOneOut CV Scores: [1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0.]\n",
      "Random Forest - LeaveOneOut Mean Accuracy: 0.7426900584795322\n",
      "SVM - KFold CV Scores: [0.8        0.55882353 0.76470588 0.58823529 0.61764706]\n",
      "SVM - KFold Mean Accuracy: 0.6658823529411765\n",
      "SVM - StratifiedKFold CV Scores: [0.65714286 0.70588235 0.76470588 0.55882353 0.76470588]\n",
      "SVM - StratifiedKFold Mean Accuracy: 0.6902521008403362\n",
      "SVM - LeaveOneOut CV Scores: [1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1.\n",
      " 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 0. 0.]\n",
      "SVM - LeaveOneOut Mean Accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Define different cross-validation techniques\n",
    "cv_techniques = [KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "                 StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "                 LeaveOneOut()]\n",
    "\n",
    "# Iterate through the models and cross-validation techniques\n",
    "for name, model in models:\n",
    "    for cv_technique in cv_techniques:\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=cv_technique, scoring='accuracy')\n",
    "        print(f\"{name} - {cv_technique.__class__.__name__} CV Scores: {cv_scores}\")\n",
    "        print(f\"{name} - {cv_technique.__class__.__name__} Mean Accuracy: {cv_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e47f831",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "Random Forest generally performs well and is more consistent across different cross-validation techniques compared to SVM.\n",
    "Leave-One-Out validation tends to produce higher accuracy but might be sensitive to outliers.\n",
    "SVM shows more variability in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ca7874d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/120 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.7021848739495798\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.7368067226890757\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.7368067226890757\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.7660504201680672\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.7660504201680672\n",
      "\n",
      "Best pipeline: RandomForestClassifier(input_matrix, bootstrap=False, criterion=gini, max_features=0.1, min_samples_leaf=2, min_samples_split=12, n_estimators=100)\n",
      "TPOT - Test Accuracy:  0.7906976744186046\n"
     ]
    }
   ],
   "source": [
    "# Run AutoML on the dataset using TPOT\n",
    "tpot = TPOTClassifier(generations=5, population_size=20, random_state=42, verbosity=2, config_dict='TPOT sparse')\n",
    "tpot.fit(X_train, y_train)\n",
    "#print(tpot.score(X_test, y_test))\n",
    "\n",
    "#Compare AutoML with Manual Models\n",
    "tpot_accuracy = accuracy_score(y_test, tpot.predict(X_test))\n",
    "print(\"TPOT - Test Accuracy: \", tpot_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97997593",
   "metadata": {},
   "source": [
    "### Comparison:\n",
    "The Random Forest model identified by the AutoML approach achieved a test accuracy of 0.791, outperforming the mean accuracy of the manually tuned Random Forest (0.732).\n",
    "\n",
    "The AutoML approach demonstrated the ability to automatically search and find a more optimal model configuration within the given time constraints compared to manual exploration.\n",
    "\n",
    "The SVM model from manual exploration had a mean accuracy of 0.667, which is lower than the test accuracy achieved by the AutoML-selected Random Forest model (0.791).\n",
    "\n",
    "In summary, the AutoML approach, in this case represented by TPOT, has provided a more optimized model configuration compared to the manually explored models for the given dataset. It highlights the effectiveness of automated approaches in finding better-performing models with less manual intervention.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
